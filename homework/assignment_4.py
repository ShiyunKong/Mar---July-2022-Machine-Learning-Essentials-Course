# -*- coding: utf-8 -*-
"""assignment 4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xTWuS5yXH_I6GjEKqYnW_prdy4lCzlrU
"""

'''
Assignment IV: 
Due: June 12 (this is a small assignment)
Pick a dataset from UCI under classification and build a neural network for the classification. 
Try more than one architecture, for example, by having different layers. Using Dense layers is meaningful for all problems. (remember: Conv2D is relevant only for rectangular data, such as images)
Play with the number of neurons and epochs to see how the network perform. 

This assignment will help you if you plan to do any neural networks for the final project. 
Use the codes provided from the lecture as a starting point. 
Enjoy
'''

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
import numpy as np
import matplotlib.pyplot as plt 
import pandas as pd 
# %matplotlib inline
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/songs_normalize.csv", sep=",")
df = df.dropna(how="any")
print("\n")
print(f"The whole dataframe looks like:\n {df}.")
print("\n")
print("The dataframe information is: ")
print(f"{df.info()}.")
print("\n")
print(f"The dataframe shape is: {df.shape}.")
X= df.iloc[:, [2,6]]
X_train = df.iloc[:,[2,6,7]]
X_4 = df.iloc[:,[2,6,7,8]]
X_5 = df.iloc[:,[2,6,7,8,9]]
X_6 = df.iloc[:,[2,6,7,8,9,10]]
X_7 = df.iloc[:,[2,6,7,8,9,10,11]]
X_8 = df.iloc[:,[2,6,7,8,9,10,11,12]]
X_9 = df.iloc[:,[2,6,7,8,9,10,11,12,13]]
X_10 = df.iloc[:,[2,6,7,8,9,10,11,12,13,14]]
X_11 = df.iloc[:,[2,6,7,8,9,10,11,12,13,14,15]]
X_12 = df.iloc[:,[2,6,7,8,9,10,11,12,13,14,15,16]]
y = df["popularity"]
lst = []

#keras1.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=2, activation='sigmoid', input_dim = 2)  ## change it to 3, 4, 5, 6, .. to see results
model.add(layer_1)
# layer 2
layer_2 = Dense(units=1, activation='sigmoid')
model.add(layer_2)


print(model.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)


# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model.fit(X,y, epochs=2, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model.predict(X))


# good to test on new data, test data.
lst.append(model.predict(X)[0])

print(lst)

#keras2.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model2 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=3, activation='sigmoid', input_dim = 3)  ## change it to 3, 4, 5, 6, .. to see results
model2.add(layer_1)
# layer 2
layer_2 = Dense(units=2, activation='sigmoid')
model2.add(layer_2)
#layer 3
layer_3 = Dense(units=1, activation='sigmoid')
model2.add(layer_3)


print(model2.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)

# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model2.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model2.fit(X_train,y, epochs=3, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model2.predict(X_train))

# good to test on new data, test data.
lst.append(model2.predict(X_train)[0])

#keras3.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model3 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=4, activation='sigmoid', input_dim = 4)  ## change it to 3, 4, 5, 6, .. to see results
model3.add(layer_1)
# layer 2
layer_2 = Dense(units=3, activation='sigmoid')
model3.add(layer_2)
#layer 3
layer_3 = Dense(units=2, activation='sigmoid')
model3.add(layer_3)
#layer 4
layer_4 = Dense(units=1, activation='sigmoid')
model3.add(layer_4)

print(model3.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)

# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model3.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model3.fit(X_4,y, epochs=4, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model3.predict(X_4))

# good to test on new data, test data.
lst.append(model3.predict(X_4)[0])

#keras4.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model4 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=5, activation='sigmoid', input_dim = 5)  ## change it to 3, 4, 5, 6, .. to see results
model4.add(layer_1)
# layer 2
layer_2 = Dense(units=4, activation='sigmoid')
model4.add(layer_2)
#layer 3
layer_3 = Dense(units=3, activation='sigmoid')
model4.add(layer_3)
#layer 4
layer_4 = Dense(units=2, activation='sigmoid')
model4.add(layer_4)
#layer 5
layer_5 = Dense(units=1, activation='sigmoid')
model4.add(layer_5)

print(model4.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_4.input_shape, layer_5.output_shape)


# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model4.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model4.fit(X_5,y, epochs=5, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model4.predict(X_5))

# good to test on new data, test data.
lst.append(model4.predict(X_5)[0])

#keras5.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model5 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=6, activation='sigmoid', input_dim = 6)  ## change it to 3, 4, 5, 6, .. to see results
model5.add(layer_1)
# layer 2
layer_2 = Dense(units=5, activation='sigmoid')
model5.add(layer_2)
#layer 3
layer_3 = Dense(units=4, activation='sigmoid')
model5.add(layer_3)
#layer 4
layer_4 = Dense(units=3, activation='sigmoid')
model5.add(layer_4)
#layer 5
layer_5 = Dense(units=2, activation='sigmoid')
model5.add(layer_5)
#layer 6
layer_6 = Dense(units=1, activation='sigmoid')
model5.add(layer_6)

print(model5.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model5.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model5.fit(X_6,y, epochs=6, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model5.predict(X_6))

# good to test on new data, test data.
lst.append(model5.predict(X_6)[0])

#keras6.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model6 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=7, activation='sigmoid', input_dim = 7)  ## change it to 3, 4, 5, 6, .. to see results
model6.add(layer_1)
# layer 2
layer_2 = Dense(units=6, activation='sigmoid')
model6.add(layer_2)
#layer 3
layer_3 = Dense(units=5, activation='sigmoid')
model6.add(layer_3)
#layer 4
layer_4 = Dense(units=4, activation='sigmoid')
model6.add(layer_4)
#layer 5
layer_5 = Dense(units=3, activation='sigmoid')
model6.add(layer_5)
#layer 6
layer_6 = Dense(units=2, activation='sigmoid')
model6.add(layer_6)
#layer 7
layer_7 = Dense(units=1, activation='sigmoid')
model6.add(layer_7)

print(model6.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model6.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model6.fit(X_7,y, epochs=7, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model6.predict(X_7))

# good to test on new data, test data.
lst.append(model6.predict(X_7)[0])

#keras7.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model7 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=8, activation='sigmoid', input_dim = 8)  ## change it to 3, 4, 5, 6, .. to see results
model7.add(layer_1)
# layer 2
layer_2 = Dense(units=7, activation='sigmoid')
model7.add(layer_2)
#layer 3
layer_3 = Dense(units=6, activation='sigmoid')
model7.add(layer_3)
#layer 4
layer_4 = Dense(units=5, activation='sigmoid')
model7.add(layer_4)
#layer 5
layer_5 = Dense(units=4, activation='sigmoid')
model7.add(layer_5)
#layer 6
layer_6 = Dense(units=3, activation='sigmoid')
model7.add(layer_6)
#layer 7
layer_7 = Dense(units=2, activation='sigmoid')
model7.add(layer_7)
#layer 8
layer_8 = Dense(units=1, activation='sigmoid')
model7.add(layer_8)

print(model7.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)
print("\n\n layer_8 : ", layer_8.input_shape, layer_8.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model7.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model7.fit(X_8,y, epochs=8, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model7.predict(X_8))

# good to test on new data, test data.
lst.append(model7.predict(X_8)[0])

#keras8.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model8 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=9, activation='sigmoid', input_dim = 9)  ## change it to 3, 4, 5, 6, .. to see results
model8.add(layer_1)
# layer 2
layer_2 = Dense(units=8, activation='sigmoid')
model8.add(layer_2)
#layer 3
layer_3 = Dense(units=7, activation='sigmoid')
model8.add(layer_3)
#layer 4
layer_4 = Dense(units=6, activation='sigmoid')
model8.add(layer_4)
#layer 5
layer_5 = Dense(units=5, activation='sigmoid')
model8.add(layer_5)
#layer 6
layer_6 = Dense(units=4, activation='sigmoid')
model8.add(layer_6)
#layer 7
layer_7 = Dense(units=3, activation='sigmoid')
model8.add(layer_7)
#layer 8
layer_8 = Dense(units=2, activation='sigmoid')
model8.add(layer_8)
#layer 9
layer_9 = Dense(units=1, activation='sigmoid')
model8.add(layer_9)

print(model8.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)
print("\n\n layer_8 : ", layer_8.input_shape, layer_8.output_shape)
print("\n\n layer_9 : ", layer_9.input_shape, layer_9.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model8.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model8.fit(X_9,y, epochs=9, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model8.predict(X_9))

# good to test on new data, test data.
lst.append(model8.predict(X_9)[0])

#keras9.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model9 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=10, activation='sigmoid', input_dim = 10)  ## change it to 3, 4, 5, 6, .. to see results
model9.add(layer_1)
# layer 2
layer_2 = Dense(units=9, activation='sigmoid')
model9.add(layer_2)
#layer 3
layer_3 = Dense(units=8, activation='sigmoid')
model9.add(layer_3)
#layer 4
layer_4 = Dense(units=7, activation='sigmoid')
model9.add(layer_4)
#layer 5
layer_5 = Dense(units=6, activation='sigmoid')
model9.add(layer_5)
#layer 6
layer_6 = Dense(units=5, activation='sigmoid')
model9.add(layer_6)
#layer 7
layer_7 = Dense(units=4, activation='sigmoid')
model9.add(layer_7)
#layer 8
layer_8 = Dense(units=3, activation='sigmoid')
model9.add(layer_8)
#layer 9
layer_9 = Dense(units=2, activation='sigmoid')
model9.add(layer_9)
#layer 10
layer_10 = Dense(units=1, activation='sigmoid')
model9.add(layer_10)

print(model9.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)
print("\n\n layer_8 : ", layer_8.input_shape, layer_8.output_shape)
print("\n\n layer_9 : ", layer_9.input_shape, layer_9.output_shape)
print("\n\n layer_10 : ", layer_10.input_shape, layer_10.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model9.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model9.fit(X_10,y, epochs=10, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model9.predict(X_10))

# good to test on new data, test data.
lst.append(model9.predict(X_10)[0])

#keras10.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model10 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=11, activation='sigmoid', input_dim = 11)  ## change it to 3, 4, 5, 6, .. to see results
model10.add(layer_1)
# layer 2
layer_2 = Dense(units=10, activation='sigmoid')
model10.add(layer_2)
#layer 3
layer_3 = Dense(units=9, activation='sigmoid')
model10.add(layer_3)
#layer 4
layer_4 = Dense(units=8, activation='sigmoid')
model10.add(layer_4)
#layer 5
layer_5 = Dense(units=7, activation='sigmoid')
model10.add(layer_5)
#layer 6
layer_6 = Dense(units=6, activation='sigmoid')
model10.add(layer_6)
#layer 7
layer_7 = Dense(units=5, activation='sigmoid')
model10.add(layer_7)
#layer 8
layer_8 = Dense(units=4, activation='sigmoid')
model10.add(layer_8)
#layer 9
layer_9 = Dense(units=3, activation='sigmoid')
model10.add(layer_9)
#layer 10
layer_10 = Dense(units=2, activation='sigmoid')
model10.add(layer_10)
#layer 11
layer_11 = Dense(units=1, activation='sigmoid')
model10.add(layer_11)

print(model10.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)
print("\n\n layer_8 : ", layer_8.input_shape, layer_8.output_shape)
print("\n\n layer_9 : ", layer_9.input_shape, layer_9.output_shape)
print("\n\n layer_10 : ", layer_10.input_shape, layer_10.output_shape)
print("\n\n layer_11 : ", layer_11.input_shape, layer_11.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model10.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model10.fit(X_11,y, epochs=11, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model10.predict(X_11))

# good to test on new data, test data.
lst.append(model10.predict(X_11)[0])

#keras11.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model11 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=12, activation='sigmoid', input_dim = 12)  ## change it to 3, 4, 5, 6, .. to see results
model11.add(layer_1)
# layer 2
layer_2 = Dense(units=11, activation='sigmoid')
model11.add(layer_2)
#layer 3
layer_3 = Dense(units=10, activation='sigmoid')
model11.add(layer_3)
#layer 4
layer_4 = Dense(units=9, activation='sigmoid')
model11.add(layer_4)
#layer 5
layer_5 = Dense(units=8, activation='sigmoid')
model11.add(layer_5)
#layer 6
layer_6 = Dense(units=7, activation='sigmoid')
model11.add(layer_6)
#layer 7
layer_7 = Dense(units=6, activation='sigmoid')
model11.add(layer_7)
#layer 8
layer_8 = Dense(units=5, activation='sigmoid')
model11.add(layer_8)
#layer 9
layer_9 = Dense(units=4, activation='sigmoid')
model11.add(layer_9)
#layer 10
layer_10 = Dense(units=3, activation='sigmoid')
model11.add(layer_10)
#layer 11
layer_11 = Dense(units=2, activation='sigmoid')
model11.add(layer_11)
#layer 12
layer_12 = Dense(units=1, activation='sigmoid')
model11.add(layer_12)

print(model11.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)
print("\n\n layer_8 : ", layer_8.input_shape, layer_8.output_shape)
print("\n\n layer_9 : ", layer_9.input_shape, layer_9.output_shape)
print("\n\n layer_10 : ", layer_10.input_shape, layer_10.output_shape)
print("\n\n layer_11 : ", layer_11.input_shape, layer_11.output_shape)
print("\n\n layer_12 : ", layer_12.input_shape, layer_12.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model11.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model11.fit(X_12,y, epochs=12, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model11.predict(X_12))

# good to test on new data, test data.
lst.append(model11.predict(X_12)[0])

#keras1.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=2, activation='sigmoid', input_dim = 2)  ## change it to 3, 4, 5, 6, .. to see results
model.add(layer_1)
# layer 2
layer_2 = Dense(units=1, activation='sigmoid')
model.add(layer_2)


print(model.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)


# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model.fit(X,y, epochs=2, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model.predict(X))


# good to test on new data, test data.
lst.append(model.predict(X)[0])

#keras2.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model2 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=1, activation='sigmoid', input_dim = 3)  ## change it to 3, 4, 5, 6, .. to see results
model2.add(layer_1)
# layer 2
layer_2 = Dense(units=2, activation='sigmoid')
model2.add(layer_2)
#layer 3
layer_3 = Dense(units=1, activation='sigmoid')
model2.add(layer_3)


print(model2.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)

# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model2.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model2.fit(X_train,y, epochs=3, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model2.predict(X_train))

# good to test on new data, test data.
lst.append(model2.predict(X_train)[0])

#keras3.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model3 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=1, activation='sigmoid', input_dim = 4)  ## change it to 3, 4, 5, 6, .. to see results
model3.add(layer_1)
# layer 2
layer_2 = Dense(units=2, activation='sigmoid')
model3.add(layer_2)
#layer 3
layer_3 = Dense(units=2, activation='sigmoid')
model3.add(layer_3)
#layer 4
layer_4 = Dense(units=1, activation='sigmoid')
model3.add(layer_4)

print(model3.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)

# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model3.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model3.fit(X_4,y, epochs=4, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model3.predict(X_4))

# good to test on new data, test data.
lst.append(model3.predict(X_4)[0])

#keras4.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model4 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=1, activation='sigmoid', input_dim = 5)  ## change it to 3, 4, 5, 6, .. to see results
model4.add(layer_1)
# layer 2
layer_2 = Dense(units=2, activation='sigmoid')
model4.add(layer_2)
#layer 3
layer_3 = Dense(units=3, activation='sigmoid')
model4.add(layer_3)
#layer 4
layer_4 = Dense(units=2, activation='sigmoid')
model4.add(layer_4)
#layer 5
layer_5 = Dense(units=1, activation='sigmoid')
model4.add(layer_5)

print(model4.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_4.input_shape, layer_5.output_shape)


# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model4.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model4.fit(X_5,y, epochs=5, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model4.predict(X_5))

# good to test on new data, test data.
lst.append(model4.predict(X_5)[0])

#keras5.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model5 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=1, activation='sigmoid', input_dim = 6)  ## change it to 3, 4, 5, 6, .. to see results
model5.add(layer_1)
# layer 2
layer_2 = Dense(units=2, activation='sigmoid')
model5.add(layer_2)
#layer 3
layer_3 = Dense(units=3, activation='sigmoid')
model5.add(layer_3)
#layer 4
layer_4 = Dense(units=3, activation='sigmoid')
model5.add(layer_4)
#layer 5
layer_5 = Dense(units=2, activation='sigmoid')
model5.add(layer_5)
#layer 6
layer_6 = Dense(units=1, activation='sigmoid')
model5.add(layer_6)

print(model5.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model5.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model5.fit(X_6,y, epochs=6, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model5.predict(X_6))

# good to test on new data, test data.
lst.append(model5.predict(X_6)[0])

#keras6.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model6 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=1, activation='sigmoid', input_dim = 7)  ## change it to 3, 4, 5, 6, .. to see results
model6.add(layer_1)
# layer 2
layer_2 = Dense(units=2, activation='sigmoid')
model6.add(layer_2)
#layer 3
layer_3 = Dense(units=3, activation='sigmoid')
model6.add(layer_3)
#layer 4
layer_4 = Dense(units=4, activation='sigmoid')
model6.add(layer_4)
#layer 5
layer_5 = Dense(units=3, activation='sigmoid')
model6.add(layer_5)
#layer 6
layer_6 = Dense(units=2, activation='sigmoid')
model6.add(layer_6)
#layer 7
layer_7 = Dense(units=1, activation='sigmoid')
model6.add(layer_7)

print(model6.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model6.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model6.fit(X_7,y, epochs=7, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model6.predict(X_7))

# good to test on new data, test data.
lst.append(model6.predict(X_7)[0])


#keras7.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model7 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=1, activation='sigmoid', input_dim = 8)  ## change it to 3, 4, 5, 6, .. to see results
model7.add(layer_1)
# layer 2
layer_2 = Dense(units=2, activation='sigmoid')
model7.add(layer_2)
#layer 3
layer_3 = Dense(units=3, activation='sigmoid')
model7.add(layer_3)
#layer 4
layer_4 = Dense(units=4, activation='sigmoid')
model7.add(layer_4)
#layer 5
layer_5 = Dense(units=4, activation='sigmoid')
model7.add(layer_5)
#layer 6
layer_6 = Dense(units=3, activation='sigmoid')
model7.add(layer_6)
#layer 7
layer_7 = Dense(units=2, activation='sigmoid')
model7.add(layer_7)
#layer 8
layer_8 = Dense(units=1, activation='sigmoid')
model7.add(layer_8)

print(model7.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)
print("\n\n layer_8 : ", layer_8.input_shape, layer_8.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model7.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model7.fit(X_8,y, epochs=8, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model7.predict(X_8))

# good to test on new data, test data.
lst.append(model7.predict(X_8)[0])

#keras8.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model8 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=1, activation='sigmoid', input_dim = 9)  ## change it to 3, 4, 5, 6, .. to see results
model8.add(layer_1)
# layer 2
layer_2 = Dense(units=2, activation='sigmoid')
model8.add(layer_2)
#layer 3
layer_3 = Dense(units=3, activation='sigmoid')
model8.add(layer_3)
#layer 4
layer_4 = Dense(units=4, activation='sigmoid')
model8.add(layer_4)
#layer 5
layer_5 = Dense(units=5, activation='sigmoid')
model8.add(layer_5)
#layer 6
layer_6 = Dense(units=4, activation='sigmoid')
model8.add(layer_6)
#layer 7
layer_7 = Dense(units=3, activation='sigmoid')
model8.add(layer_7)
#layer 8
layer_8 = Dense(units=2, activation='sigmoid')
model8.add(layer_8)
#layer 9
layer_9 = Dense(units=1, activation='sigmoid')
model8.add(layer_9)

print(model8.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)
print("\n\n layer_8 : ", layer_8.input_shape, layer_8.output_shape)
print("\n\n layer_9 : ", layer_9.input_shape, layer_9.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model8.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model8.fit(X_9,y, epochs=9, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model8.predict(X_9))

# good to test on new data, test data.
lst.append(model8.predict(X_9)[0])

#keras9.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model9 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=1, activation='sigmoid', input_dim = 10)  ## change it to 3, 4, 5, 6, .. to see results
model9.add(layer_1)
# layer 2
layer_2 = Dense(units=2, activation='sigmoid')
model9.add(layer_2)
#layer 3
layer_3 = Dense(units=3, activation='sigmoid')
model9.add(layer_3)
#layer 4
layer_4 = Dense(units=4, activation='sigmoid')
model9.add(layer_4)
#layer 5
layer_5 = Dense(units=5, activation='sigmoid')
model9.add(layer_5)
#layer 6
layer_6 = Dense(units=5, activation='sigmoid')
model9.add(layer_6)
#layer 7
layer_7 = Dense(units=4, activation='sigmoid')
model9.add(layer_7)
#layer 8
layer_8 = Dense(units=3, activation='sigmoid')
model9.add(layer_8)
#layer 9
layer_9 = Dense(units=2, activation='sigmoid')
model9.add(layer_9)
#layer 10
layer_10 = Dense(units=1, activation='sigmoid')
model9.add(layer_10)

print(model9.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)
print("\n\n layer_8 : ", layer_8.input_shape, layer_8.output_shape)
print("\n\n layer_9 : ", layer_9.input_shape, layer_9.output_shape)
print("\n\n layer_10 : ", layer_10.input_shape, layer_10.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model9.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model9.fit(X_10,y, epochs=10, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model9.predict(X_10))

# good to test on new data, test data.
lst.append(model9.predict(X_10)[0])

#keras10.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model10 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=1, activation='sigmoid', input_dim = 11)  ## change it to 3, 4, 5, 6, .. to see results
model10.add(layer_1)
# layer 2
layer_2 = Dense(units=2, activation='sigmoid')
model10.add(layer_2)
#layer 3
layer_3 = Dense(units=3, activation='sigmoid')
model10.add(layer_3)
#layer 4
layer_4 = Dense(units=4, activation='sigmoid')
model10.add(layer_4)
#layer 5
layer_5 = Dense(units=5, activation='sigmoid')
model10.add(layer_5)
#layer 6
layer_6 = Dense(units=6, activation='sigmoid')
model10.add(layer_6)
#layer 7
layer_7 = Dense(units=5, activation='sigmoid')
model10.add(layer_7)
#layer 8
layer_8 = Dense(units=4, activation='sigmoid')
model10.add(layer_8)
#layer 9
layer_9 = Dense(units=3, activation='sigmoid')
model10.add(layer_9)
#layer 10
layer_10 = Dense(units=2, activation='sigmoid')
model10.add(layer_10)
#layer 11
layer_11 = Dense(units=1, activation='sigmoid')
model10.add(layer_11)

print(model10.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)
print("\n\n layer_8 : ", layer_8.input_shape, layer_8.output_shape)
print("\n\n layer_9 : ", layer_9.input_shape, layer_9.output_shape)
print("\n\n layer_10 : ", layer_10.input_shape, layer_10.output_shape)
print("\n\n layer_11 : ", layer_11.input_shape, layer_11.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model10.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model10.fit(X_11,y, epochs=11, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model10.predict(X_11))

# good to test on new data, test data.
lst.append(model10.predict(X_11)[0])

#keras11.py

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.utils import plot_model
import numpy as np

# define first architecture of the model
#
model11 = Sequential()    # creates an empty sequential model 
# layer 1
layer_1 = Dense(units=1, activation='sigmoid', input_dim = 12)  ## change it to 3, 4, 5, 6, .. to see results
model11.add(layer_1)
# layer 2
layer_2 = Dense(units=2, activation='sigmoid')
model11.add(layer_2)
#layer 3
layer_3 = Dense(units=3, activation='sigmoid')
model11.add(layer_3)
#layer 4
layer_4 = Dense(units=4, activation='sigmoid')
model11.add(layer_4)
#layer 5
layer_5 = Dense(units=5, activation='sigmoid')
model11.add(layer_5)
#layer 6
layer_6 = Dense(units=6, activation='sigmoid')
model11.add(layer_6)
#layer 7
layer_7 = Dense(units=6, activation='sigmoid')
model11.add(layer_7)
#layer 8
layer_8 = Dense(units=5, activation='sigmoid')
model11.add(layer_8)
#layer 9
layer_9 = Dense(units=4, activation='sigmoid')
model11.add(layer_9)
#layer 10
layer_10 = Dense(units=3, activation='sigmoid')
model11.add(layer_10)
#layer 11
layer_11 = Dense(units=2, activation='sigmoid')
model11.add(layer_11)
#layer 12
layer_12 = Dense(units=1, activation='sigmoid')
model11.add(layer_12)

print(model11.summary())  # to verify model structure

print("\n\n layer_1 : ", layer_1.input_shape, layer_1.output_shape)
print("\n\n layer_2 : ", layer_2.input_shape, layer_2.output_shape)
print("\n\n layer_3 : ", layer_3.input_shape, layer_3.output_shape)
print("\n\n layer_4 : ", layer_4.input_shape, layer_4.output_shape)
print("\n\n layer_5 : ", layer_5.input_shape, layer_5.output_shape)
print("\n\n layer_6 : ", layer_6.input_shape, layer_6.output_shape)
print("\n\n layer_7 : ", layer_7.input_shape, layer_7.output_shape)
print("\n\n layer_8 : ", layer_8.input_shape, layer_8.output_shape)
print("\n\n layer_9 : ", layer_9.input_shape, layer_9.output_shape)
print("\n\n layer_10 : ", layer_10.input_shape, layer_10.output_shape)
print("\n\n layer_11 : ", layer_11.input_shape, layer_11.output_shape)
print("\n\n layer_12 : ", layer_12.input_shape, layer_12.output_shape)



# tell Keras what loss,optimizer
opt = keras.optimizers.Adam(learning_rate=0.01)
model11.compile(loss='mean_squared_error', optimizer =opt)
# at this stage, the model is not done yet.

# now for training data

# np.random.seed(9)
# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
# y = np.array([[0],[1],[1],[0]])

# training
model11.fit(X_12,y, epochs=12, verbose=2,  max_queue_size = 40)



# now the model is ready. you can use it for prediction

# we check it on training data
print(model11.predict(X_12))

# good to test on new data, test data.
lst.append(model11.predict(X_12)[0])

# regression analysis
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
X_train = [2,3,4,5,6,7,8,10,11,12,13]
y_train = [0.94913673, 0.9801116, 0.9924147, 0.9930438, 0.9895524, 0.99626696, 0.9925206, 0.99731386, 0.9982563, 0.97462773, 0.9958976]
X_test = [2,3,4,5,6,7,8,10,11,12,13]
y_test = [0.76626456, 0.84791243, 0.9827498, 0.988194, 0.99446905, 0.99014926, 0.98769546, 0.9972669, 0.9947778, 0.9973445, 0.99845743]

poly1 = np.poly1d(np.polyfit(X_train, y_train, 6))
poly2 = np.poly1d(np.polyfit(X_test, y_test, 6))
line = np.linspace(1, 22, 100)
plt.figure(figsize=(6,10))
plt.scatter(X_train, y_train, label='True Points')
plt.scatter(X_test, y_test, label='True Points')
plt.plot(line, poly1(line))
plt.plot(line, poly2(line))
plt.title('Comparison between Accuracies of 2 Types of Neuro-network Architecture')
plt.xlabel('Inputs')
plt.ylabel('Accuracy(0~1)')
plt.axis([0, 15, 0.7, 1.4])
plt.grid(True)
plt.legend()
plt.show()

print(X_train
      )