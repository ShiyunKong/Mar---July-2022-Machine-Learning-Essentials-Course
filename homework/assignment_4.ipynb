{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "assignment 4.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwTcLhGc1IgD"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Assignment IV: \n",
    "Due: June 12 (this is a small assignment)\n",
    "Pick a dataset from UCI under classification and build a neural network for the classification. \n",
    "Try more than one architecture, for example, by having different layers. Using Dense layers is meaningful for all problems. (remember: Conv2D is relevant only for rectangular data, such as images)\n",
    "Play with the number of neurons and epochs to see how the network perform. \n",
    "\n",
    "This assignment will help you if you plan to do any neural networks for the final project. \n",
    "Use the codes provided from the lecture as a starting point. \n",
    "Enjoy\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "%matplotlib inline\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/songs_normalize.csv\", sep=\",\")\n",
    "df = df.dropna(how=\"any\")\n",
    "print(\"\\n\")\n",
    "print(f\"The whole dataframe looks like:\\n {df}.\")\n",
    "print(\"\\n\")\n",
    "print(\"The dataframe information is: \")\n",
    "print(f\"{df.info()}.\")\n",
    "print(\"\\n\")\n",
    "print(f\"The dataframe shape is: {df.shape}.\")\n",
    "X= df.iloc[:, [2,6]]\n",
    "X_train = df.iloc[:,[2,6,7]]\n",
    "X_4 = df.iloc[:,[2,6,7,8]]\n",
    "X_5 = df.iloc[:,[2,6,7,8,9]]\n",
    "X_6 = df.iloc[:,[2,6,7,8,9,10]]\n",
    "X_7 = df.iloc[:,[2,6,7,8,9,10,11]]\n",
    "X_8 = df.iloc[:,[2,6,7,8,9,10,11,12]]\n",
    "X_9 = df.iloc[:,[2,6,7,8,9,10,11,12,13]]\n",
    "X_10 = df.iloc[:,[2,6,7,8,9,10,11,12,13,14]]\n",
    "X_11 = df.iloc[:,[2,6,7,8,9,10,11,12,13,14,15]]\n",
    "X_12 = df.iloc[:,[2,6,7,8,9,10,11,12,13,14,15,16]]\n",
    "y = df[\"popularity\"]\n",
    "lst = []"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEZpcrLMd2vb",
    "outputId": "94d0f2a7-7b9e-48e4-f0ee-007abe91e2ca"
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "\n",
      "\n",
      "The whole dataframe looks like:\n",
      "               artist                                    song  duration_ms  \\\n",
      "0     Britney Spears                  Oops!...I Did It Again       211160   \n",
      "1          blink-182                    All The Small Things       167066   \n",
      "2         Faith Hill                                 Breathe       250546   \n",
      "3           Bon Jovi                            It's My Life       224493   \n",
      "4             *NSYNC                             Bye Bye Bye       200560   \n",
      "...              ...                                     ...          ...   \n",
      "1995  Jonas Brothers                                  Sucker       181026   \n",
      "1996    Taylor Swift                            Cruel Summer       178426   \n",
      "1997    Blanco Brown                              The Git Up       200593   \n",
      "1998       Sam Smith  Dancing With A Stranger (with Normani)       171029   \n",
      "1999     Post Malone                                 Circles       215280   \n",
      "\n",
      "      explicit  year  popularity  danceability  energy  key  loudness  mode  \\\n",
      "0        False  2000          77         0.751   0.834    1    -5.444     0   \n",
      "1        False  1999          79         0.434   0.897    0    -4.918     1   \n",
      "2        False  1999          66         0.529   0.496    7    -9.007     1   \n",
      "3        False  2000          78         0.551   0.913    0    -4.063     0   \n",
      "4        False  2000          65         0.614   0.928    8    -4.806     0   \n",
      "...        ...   ...         ...           ...     ...  ...       ...   ...   \n",
      "1995     False  2019          79         0.842   0.734    1    -5.065     0   \n",
      "1996     False  2019          78         0.552   0.702    9    -5.707     1   \n",
      "1997     False  2019          69         0.847   0.678    9    -8.635     1   \n",
      "1998     False  2019          75         0.741   0.520    8    -7.513     1   \n",
      "1999     False  2019          85         0.695   0.762    0    -3.497     1   \n",
      "\n",
      "      speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
      "0          0.0437        0.3000          0.000018    0.3550    0.894   95.053   \n",
      "1          0.0488        0.0103          0.000000    0.6120    0.684  148.726   \n",
      "2          0.0290        0.1730          0.000000    0.2510    0.278  136.859   \n",
      "3          0.0466        0.0263          0.000013    0.3470    0.544  119.992   \n",
      "4          0.0516        0.0408          0.001040    0.0845    0.879  172.656   \n",
      "...           ...           ...               ...       ...      ...      ...   \n",
      "1995       0.0588        0.0427          0.000000    0.1060    0.952  137.958   \n",
      "1996       0.1570        0.1170          0.000021    0.1050    0.564  169.994   \n",
      "1997       0.1090        0.0669          0.000000    0.2740    0.811   97.984   \n",
      "1998       0.0656        0.4500          0.000002    0.2220    0.347  102.998   \n",
      "1999       0.0395        0.1920          0.002440    0.0863    0.553  120.042   \n",
      "\n",
      "                 genre  \n",
      "0                  pop  \n",
      "1            rock, pop  \n",
      "2         pop, country  \n",
      "3          rock, metal  \n",
      "4                  pop  \n",
      "...                ...  \n",
      "1995               pop  \n",
      "1996               pop  \n",
      "1997  hip hop, country  \n",
      "1998               pop  \n",
      "1999           hip hop  \n",
      "\n",
      "[2000 rows x 18 columns].\n",
      "\n",
      "\n",
      "The dataframe information is: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 0 to 1999\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   artist            2000 non-null   object \n",
      " 1   song              2000 non-null   object \n",
      " 2   duration_ms       2000 non-null   int64  \n",
      " 3   explicit          2000 non-null   bool   \n",
      " 4   year              2000 non-null   int64  \n",
      " 5   popularity        2000 non-null   int64  \n",
      " 6   danceability      2000 non-null   float64\n",
      " 7   energy            2000 non-null   float64\n",
      " 8   key               2000 non-null   int64  \n",
      " 9   loudness          2000 non-null   float64\n",
      " 10  mode              2000 non-null   int64  \n",
      " 11  speechiness       2000 non-null   float64\n",
      " 12  acousticness      2000 non-null   float64\n",
      " 13  instrumentalness  2000 non-null   float64\n",
      " 14  liveness          2000 non-null   float64\n",
      " 15  valence           2000 non-null   float64\n",
      " 16  tempo             2000 non-null   float64\n",
      " 17  genre             2000 non-null   object \n",
      "dtypes: bool(1), float64(9), int64(5), object(3)\n",
      "memory usage: 283.2+ KB\n",
      "None.\n",
      "\n",
      "\n",
      "The dataframe shape is: (2000, 18).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras1.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=2, activation='sigmoid', input_dim = 2)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=1, activation='sigmoid')\n",
    "model.add(layer_2)\n",
    "\n",
    "\n",
    "print(model.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model.fit(X,y, epochs=2, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model.predict(X))\n",
    "\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model.predict(X)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIZhO_ZP1QMv",
    "outputId": "12d9cc21-8c8d-49dc-e355-e11d3e069fdb"
   },
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_52 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 2) (None, 2)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 2) (None, 1)\n",
      "Epoch 1/2\n",
      "63/63 - 0s - loss: 3950.9138 - 400ms/epoch - 6ms/step\n",
      "Epoch 2/2\n",
      "63/63 - 0s - loss: 3930.3611 - 73ms/epoch - 1ms/step\n",
      "[[0.94913673]\n",
      " [0.94913673]\n",
      " [0.94913673]\n",
      " ...\n",
      " [0.94913673]\n",
      " [0.94913673]\n",
      " [0.94913673]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(lst)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7ijmEry1FN0",
    "outputId": "8bb417c1-549a-4519-e66c-7b3006bed3d5"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[array([0.9570153], dtype=float32)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras2.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model2 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=3, activation='sigmoid', input_dim = 3)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model2.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=2, activation='sigmoid')\n",
    "model2.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=1, activation='sigmoid')\n",
    "model2.add(layer_3)\n",
    "\n",
    "\n",
    "print(model2.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model2.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model2.fit(X_train,y, epochs=3, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model2.predict(X_train))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model2.predict(X_train)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5DWLWL5xwJ4",
    "outputId": "2664a575-a3f4-48be-bd84-9f1ca2bc583b"
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23\n",
      "Trainable params: 23\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 3) (None, 3)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 2) (None, 1)\n",
      "Epoch 1/3\n",
      "63/63 - 0s - loss: 3957.8787 - 422ms/epoch - 7ms/step\n",
      "Epoch 2/3\n",
      "63/63 - 0s - loss: 3932.1785 - 77ms/epoch - 1ms/step\n",
      "Epoch 3/3\n",
      "63/63 - 0s - loss: 3924.7437 - 73ms/epoch - 1ms/step\n",
      "[[0.9801116]\n",
      " [0.9801116]\n",
      " [0.9801116]\n",
      " ...\n",
      " [0.9801116]\n",
      " [0.9801116]\n",
      " [0.9801116]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras3.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model3 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=4, activation='sigmoid', input_dim = 4)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model3.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=3, activation='sigmoid')\n",
    "model3.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=2, activation='sigmoid')\n",
    "model3.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=1, activation='sigmoid')\n",
    "model3.add(layer_4)\n",
    "\n",
    "print(model3.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model3.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model3.fit(X_4,y, epochs=4, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model3.predict(X_4))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model3.predict(X_4)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zCy0Xfx1zsGE",
    "outputId": "6e041265-a745-4c95-8bdb-8928b54110db"
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_57 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46\n",
      "Trainable params: 46\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 4) (None, 4)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 2) (None, 1)\n",
      "Epoch 1/4\n",
      "63/63 - 1s - loss: 3941.5779 - 507ms/epoch - 8ms/step\n",
      "Epoch 2/4\n",
      "63/63 - 0s - loss: 3925.8711 - 75ms/epoch - 1ms/step\n",
      "Epoch 3/4\n",
      "63/63 - 0s - loss: 3922.9968 - 85ms/epoch - 1ms/step\n",
      "Epoch 4/4\n",
      "63/63 - 0s - loss: 3922.0918 - 86ms/epoch - 1ms/step\n",
      "[[0.9924147]\n",
      " [0.9924147]\n",
      " [0.9924147]\n",
      " ...\n",
      " [0.9924147]\n",
      " [0.9924147]\n",
      " [0.9924147]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras4.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model4 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=5, activation='sigmoid', input_dim = 5)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model4.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=4, activation='sigmoid')\n",
    "model4.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=3, activation='sigmoid')\n",
    "model4.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=2, activation='sigmoid')\n",
    "model4.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=1, activation='sigmoid')\n",
    "model4.add(layer_5)\n",
    "\n",
    "print(model4.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_4.input_shape, layer_5.output_shape)\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model4.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model4.fit(X_5,y, epochs=5, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model4.predict(X_5))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model4.predict(X_5)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxXdrYGU2OwM",
    "outputId": "1ef473a3-5d35-4fa2-fda3-49d180e8e2f0"
   },
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 5) (None, 5)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 3) (None, 1)\n",
      "Epoch 1/5\n",
      "63/63 - 1s - loss: 3947.9326 - 890ms/epoch - 14ms/step\n",
      "Epoch 2/5\n",
      "63/63 - 0s - loss: 3927.5122 - 121ms/epoch - 2ms/step\n",
      "Epoch 3/5\n",
      "63/63 - 0s - loss: 3923.4902 - 113ms/epoch - 2ms/step\n",
      "Epoch 4/5\n",
      "63/63 - 0s - loss: 3922.4038 - 114ms/epoch - 2ms/step\n",
      "Epoch 5/5\n",
      "63/63 - 0s - loss: 3921.9275 - 112ms/epoch - 2ms/step\n",
      "[[0.9930438]\n",
      " [0.9930438]\n",
      " [0.9930438]\n",
      " ...\n",
      " [0.9930438]\n",
      " [0.9930438]\n",
      " [0.9930438]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras5.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model5 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=6, activation='sigmoid', input_dim = 6)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model5.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=5, activation='sigmoid')\n",
    "model5.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=4, activation='sigmoid')\n",
    "model5.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=3, activation='sigmoid')\n",
    "model5.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=2, activation='sigmoid')\n",
    "model5.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=1, activation='sigmoid')\n",
    "model5.add(layer_6)\n",
    "\n",
    "print(model5.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model5.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model5.fit(X_6,y, epochs=6, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model5.predict(X_6))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model5.predict(X_6)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4nBddyw29f8",
    "outputId": "c6a53348-28e0-4e74-d34d-7a380f71cf0d"
   },
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_76 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 127\n",
      "Trainable params: 127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 6) (None, 6)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 6) (None, 5)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 2) (None, 1)\n",
      "Epoch 1/6\n",
      "63/63 - 1s - loss: 3944.8867 - 1s/epoch - 22ms/step\n",
      "Epoch 2/6\n",
      "63/63 - 0s - loss: 3928.2922 - 181ms/epoch - 3ms/step\n",
      "Epoch 3/6\n",
      "63/63 - 0s - loss: 3924.9473 - 138ms/epoch - 2ms/step\n",
      "Epoch 4/6\n",
      "63/63 - 0s - loss: 3923.5515 - 187ms/epoch - 3ms/step\n",
      "Epoch 5/6\n",
      "63/63 - 0s - loss: 3922.8049 - 152ms/epoch - 2ms/step\n",
      "Epoch 6/6\n",
      "63/63 - 0s - loss: 3922.3523 - 118ms/epoch - 2ms/step\n",
      "[[0.9895524]\n",
      " [0.9895524]\n",
      " [0.9895524]\n",
      " ...\n",
      " [0.9895524]\n",
      " [0.9895524]\n",
      " [0.9895524]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras6.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model6 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=7, activation='sigmoid', input_dim = 7)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model6.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=6, activation='sigmoid')\n",
    "model6.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=5, activation='sigmoid')\n",
    "model6.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=4, activation='sigmoid')\n",
    "model6.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=3, activation='sigmoid')\n",
    "model6.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=2, activation='sigmoid')\n",
    "model6.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=1, activation='sigmoid')\n",
    "model6.add(layer_7)\n",
    "\n",
    "print(model6.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model6.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model6.fit(X_7,y, epochs=7, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model6.predict(X_7))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model6.predict(X_7)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6eIx6MqV3bs2",
    "outputId": "aa10879c-0424-42f5-c919-b57980fac26e"
   },
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_89 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 189\n",
      "Trainable params: 189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 7) (None, 7)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 7) (None, 6)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 6) (None, 5)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 2) (None, 1)\n",
      "Epoch 1/7\n",
      "63/63 - 1s - loss: 3940.4685 - 681ms/epoch - 11ms/step\n",
      "Epoch 2/7\n",
      "63/63 - 0s - loss: 3925.6255 - 96ms/epoch - 2ms/step\n",
      "Epoch 3/7\n",
      "63/63 - 0s - loss: 3922.9998 - 88ms/epoch - 1ms/step\n",
      "Epoch 4/7\n",
      "63/63 - 0s - loss: 3922.1890 - 91ms/epoch - 1ms/step\n",
      "Epoch 5/7\n",
      "63/63 - 0s - loss: 3921.8047 - 81ms/epoch - 1ms/step\n",
      "Epoch 6/7\n",
      "63/63 - 0s - loss: 3921.5850 - 105ms/epoch - 2ms/step\n",
      "Epoch 7/7\n",
      "63/63 - 0s - loss: 3921.4448 - 84ms/epoch - 1ms/step\n",
      "[[0.99626696]\n",
      " [0.99626696]\n",
      " [0.99626696]\n",
      " ...\n",
      " [0.99626696]\n",
      " [0.99626696]\n",
      " [0.99626696]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras7.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model7 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=8, activation='sigmoid', input_dim = 8)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model7.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=7, activation='sigmoid')\n",
    "model7.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=6, activation='sigmoid')\n",
    "model7.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=5, activation='sigmoid')\n",
    "model7.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=4, activation='sigmoid')\n",
    "model7.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=3, activation='sigmoid')\n",
    "model7.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=2, activation='sigmoid')\n",
    "model7.add(layer_7)\n",
    "#layer 8\n",
    "layer_8 = Dense(units=1, activation='sigmoid')\n",
    "model7.add(layer_8)\n",
    "\n",
    "print(model7.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "print(\"\\n\\n layer_8 : \", layer_8.input_shape, layer_8.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model7.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model7.fit(X_8,y, epochs=8, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model7.predict(X_8))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model7.predict(X_8)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMW7laZE39Bx",
    "outputId": "bd7f6d99-75ce-462d-efb2-50d685026871"
   },
   "execution_count": 46,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_96 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 268\n",
      "Trainable params: 268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 8) (None, 8)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 8) (None, 7)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 7) (None, 6)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 6) (None, 5)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_8 :  (None, 2) (None, 1)\n",
      "Epoch 1/8\n",
      "63/63 - 1s - loss: 3949.7012 - 1s/epoch - 18ms/step\n",
      "Epoch 2/8\n",
      "63/63 - 0s - loss: 3929.3342 - 147ms/epoch - 2ms/step\n",
      "Epoch 3/8\n",
      "63/63 - 0s - loss: 3925.3159 - 149ms/epoch - 2ms/step\n",
      "Epoch 4/8\n",
      "63/63 - 0s - loss: 3923.7764 - 127ms/epoch - 2ms/step\n",
      "Epoch 5/8\n",
      "63/63 - 0s - loss: 3922.9646 - 166ms/epoch - 3ms/step\n",
      "Epoch 6/8\n",
      "63/63 - 0s - loss: 3922.4724 - 157ms/epoch - 2ms/step\n",
      "Epoch 7/8\n",
      "63/63 - 0s - loss: 3922.1504 - 111ms/epoch - 2ms/step\n",
      "Epoch 8/8\n",
      "63/63 - 0s - loss: 3921.9233 - 128ms/epoch - 2ms/step\n",
      "[[0.9925206]\n",
      " [0.9925206]\n",
      " [0.9925206]\n",
      " ...\n",
      " [0.9925206]\n",
      " [0.9925206]\n",
      " [0.9925206]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras8.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model8 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=9, activation='sigmoid', input_dim = 9)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model8.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=8, activation='sigmoid')\n",
    "model8.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=7, activation='sigmoid')\n",
    "model8.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=6, activation='sigmoid')\n",
    "model8.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=5, activation='sigmoid')\n",
    "model8.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=4, activation='sigmoid')\n",
    "model8.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=3, activation='sigmoid')\n",
    "model8.add(layer_7)\n",
    "#layer 8\n",
    "layer_8 = Dense(units=2, activation='sigmoid')\n",
    "model8.add(layer_8)\n",
    "#layer 9\n",
    "layer_9 = Dense(units=1, activation='sigmoid')\n",
    "model8.add(layer_9)\n",
    "\n",
    "print(model8.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "print(\"\\n\\n layer_8 : \", layer_8.input_shape, layer_8.output_shape)\n",
    "print(\"\\n\\n layer_9 : \", layer_9.input_shape, layer_9.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model8.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model8.fit(X_9,y, epochs=9, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model8.predict(X_9))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model8.predict(X_9)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muhDr4xF5EKh",
    "outputId": "a546cc0e-9a3c-47b4-f3f9-d02b06164276"
   },
   "execution_count": 47,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_104 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 9) (None, 9)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 9) (None, 8)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 8) (None, 7)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 7) (None, 6)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 6) (None, 5)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_8 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_9 :  (None, 2) (None, 1)\n",
      "Epoch 1/9\n",
      "63/63 - 1s - loss: 3944.8179 - 1s/epoch - 23ms/step\n",
      "Epoch 2/9\n",
      "63/63 - 0s - loss: 3926.1145 - 159ms/epoch - 3ms/step\n",
      "Epoch 3/9\n",
      "63/63 - 0s - loss: 3923.1353 - 151ms/epoch - 2ms/step\n",
      "Epoch 4/9\n",
      "63/63 - 0s - loss: 3922.2520 - 153ms/epoch - 2ms/step\n",
      "Epoch 5/9\n",
      "63/63 - 0s - loss: 3921.8450 - 132ms/epoch - 2ms/step\n",
      "Epoch 6/9\n",
      "63/63 - 0s - loss: 3921.6138 - 153ms/epoch - 2ms/step\n",
      "Epoch 7/9\n",
      "63/63 - 0s - loss: 3921.4690 - 105ms/epoch - 2ms/step\n",
      "Epoch 8/9\n",
      "63/63 - 0s - loss: 3921.3684 - 107ms/epoch - 2ms/step\n",
      "Epoch 9/9\n",
      "63/63 - 0s - loss: 3921.2974 - 100ms/epoch - 2ms/step\n",
      "[[0.99731386]\n",
      " [0.99731386]\n",
      " [0.99731386]\n",
      " ...\n",
      " [0.99731386]\n",
      " [0.99731386]\n",
      " [0.99731386]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras9.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model9 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=10, activation='sigmoid', input_dim = 10)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model9.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=9, activation='sigmoid')\n",
    "model9.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=8, activation='sigmoid')\n",
    "model9.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=7, activation='sigmoid')\n",
    "model9.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=6, activation='sigmoid')\n",
    "model9.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=5, activation='sigmoid')\n",
    "model9.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=4, activation='sigmoid')\n",
    "model9.add(layer_7)\n",
    "#layer 8\n",
    "layer_8 = Dense(units=3, activation='sigmoid')\n",
    "model9.add(layer_8)\n",
    "#layer 9\n",
    "layer_9 = Dense(units=2, activation='sigmoid')\n",
    "model9.add(layer_9)\n",
    "#layer 10\n",
    "layer_10 = Dense(units=1, activation='sigmoid')\n",
    "model9.add(layer_10)\n",
    "\n",
    "print(model9.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "print(\"\\n\\n layer_8 : \", layer_8.input_shape, layer_8.output_shape)\n",
    "print(\"\\n\\n layer_9 : \", layer_9.input_shape, layer_9.output_shape)\n",
    "print(\"\\n\\n layer_10 : \", layer_10.input_shape, layer_10.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model9.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model9.fit(X_10,y, epochs=10, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model9.predict(X_10))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model9.predict(X_10)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ELxrvx96EKj",
    "outputId": "80daa5c3-33ad-45fc-edf1-3ba1521c2c18"
   },
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_113 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 485\n",
      "Trainable params: 485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 10) (None, 10)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 10) (None, 9)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 9) (None, 8)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 8) (None, 7)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 7) (None, 6)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 6) (None, 5)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_8 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_9 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_10 :  (None, 2) (None, 1)\n",
      "Epoch 1/10\n",
      "63/63 - 1s - loss: 3935.0068 - 1s/epoch - 17ms/step\n",
      "Epoch 2/10\n",
      "63/63 - 0s - loss: 3924.1013 - 199ms/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "63/63 - 0s - loss: 3922.4802 - 243ms/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "63/63 - 0s - loss: 3921.9070 - 186ms/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "63/63 - 0s - loss: 3921.6206 - 193ms/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "63/63 - 0s - loss: 3921.4521 - 186ms/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "63/63 - 0s - loss: 3921.3440 - 130ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "63/63 - 0s - loss: 3921.2690 - 221ms/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "63/63 - 0s - loss: 3921.2131 - 195ms/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "63/63 - 0s - loss: 3921.1738 - 188ms/epoch - 3ms/step\n",
      "[[0.9982563]\n",
      " [0.9982563]\n",
      " [0.9982563]\n",
      " ...\n",
      " [0.9982563]\n",
      " [0.9982563]\n",
      " [0.9982563]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras10.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model10 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=11, activation='sigmoid', input_dim = 11)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model10.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=10, activation='sigmoid')\n",
    "model10.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=9, activation='sigmoid')\n",
    "model10.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=8, activation='sigmoid')\n",
    "model10.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=7, activation='sigmoid')\n",
    "model10.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=6, activation='sigmoid')\n",
    "model10.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=5, activation='sigmoid')\n",
    "model10.add(layer_7)\n",
    "#layer 8\n",
    "layer_8 = Dense(units=4, activation='sigmoid')\n",
    "model10.add(layer_8)\n",
    "#layer 9\n",
    "layer_9 = Dense(units=3, activation='sigmoid')\n",
    "model10.add(layer_9)\n",
    "#layer 10\n",
    "layer_10 = Dense(units=2, activation='sigmoid')\n",
    "model10.add(layer_10)\n",
    "#layer 11\n",
    "layer_11 = Dense(units=1, activation='sigmoid')\n",
    "model10.add(layer_11)\n",
    "\n",
    "print(model10.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "print(\"\\n\\n layer_8 : \", layer_8.input_shape, layer_8.output_shape)\n",
    "print(\"\\n\\n layer_9 : \", layer_9.input_shape, layer_9.output_shape)\n",
    "print(\"\\n\\n layer_10 : \", layer_10.input_shape, layer_10.output_shape)\n",
    "print(\"\\n\\n layer_11 : \", layer_11.input_shape, layer_11.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model10.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model10.fit(X_11,y, epochs=11, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model10.predict(X_11))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model10.predict(X_11)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhgA7YS86kdT",
    "outputId": "64a13711-f305-48d5-d07c-9292dbf33b23"
   },
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_123 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 10)                120       \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 627\n",
      "Trainable params: 627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 11) (None, 11)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 11) (None, 10)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 10) (None, 9)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 9) (None, 8)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 8) (None, 7)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 7) (None, 6)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 6) (None, 5)\n",
      "\n",
      "\n",
      " layer_8 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_9 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_10 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_11 :  (None, 2) (None, 1)\n",
      "Epoch 1/11\n",
      "63/63 - 1s - loss: 3980.1460 - 1s/epoch - 22ms/step\n",
      "Epoch 2/11\n",
      "63/63 - 0s - loss: 3955.3792 - 189ms/epoch - 3ms/step\n",
      "Epoch 3/11\n",
      "63/63 - 0s - loss: 3943.6619 - 165ms/epoch - 3ms/step\n",
      "Epoch 4/11\n",
      "63/63 - 0s - loss: 3936.6299 - 164ms/epoch - 3ms/step\n",
      "Epoch 5/11\n",
      "63/63 - 0s - loss: 3932.3201 - 211ms/epoch - 3ms/step\n",
      "Epoch 6/11\n",
      "63/63 - 0s - loss: 3929.5562 - 193ms/epoch - 3ms/step\n",
      "Epoch 7/11\n",
      "63/63 - 0s - loss: 3927.7014 - 204ms/epoch - 3ms/step\n",
      "Epoch 8/11\n",
      "63/63 - 0s - loss: 3926.3982 - 149ms/epoch - 2ms/step\n",
      "Epoch 9/11\n",
      "63/63 - 0s - loss: 3925.4480 - 232ms/epoch - 4ms/step\n",
      "Epoch 10/11\n",
      "63/63 - 0s - loss: 3924.7322 - 399ms/epoch - 6ms/step\n",
      "Epoch 11/11\n",
      "63/63 - 0s - loss: 3924.1780 - 200ms/epoch - 3ms/step\n",
      "[[0.97462773]\n",
      " [0.97462773]\n",
      " [0.97462773]\n",
      " ...\n",
      " [0.97462773]\n",
      " [0.97462773]\n",
      " [0.97462773]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras11.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model11 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=12, activation='sigmoid', input_dim = 12)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model11.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=11, activation='sigmoid')\n",
    "model11.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=10, activation='sigmoid')\n",
    "model11.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=9, activation='sigmoid')\n",
    "model11.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=8, activation='sigmoid')\n",
    "model11.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=7, activation='sigmoid')\n",
    "model11.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=6, activation='sigmoid')\n",
    "model11.add(layer_7)\n",
    "#layer 8\n",
    "layer_8 = Dense(units=5, activation='sigmoid')\n",
    "model11.add(layer_8)\n",
    "#layer 9\n",
    "layer_9 = Dense(units=4, activation='sigmoid')\n",
    "model11.add(layer_9)\n",
    "#layer 10\n",
    "layer_10 = Dense(units=3, activation='sigmoid')\n",
    "model11.add(layer_10)\n",
    "#layer 11\n",
    "layer_11 = Dense(units=2, activation='sigmoid')\n",
    "model11.add(layer_11)\n",
    "#layer 12\n",
    "layer_12 = Dense(units=1, activation='sigmoid')\n",
    "model11.add(layer_12)\n",
    "\n",
    "print(model11.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "print(\"\\n\\n layer_8 : \", layer_8.input_shape, layer_8.output_shape)\n",
    "print(\"\\n\\n layer_9 : \", layer_9.input_shape, layer_9.output_shape)\n",
    "print(\"\\n\\n layer_10 : \", layer_10.input_shape, layer_10.output_shape)\n",
    "print(\"\\n\\n layer_11 : \", layer_11.input_shape, layer_11.output_shape)\n",
    "print(\"\\n\\n layer_12 : \", layer_12.input_shape, layer_12.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model11.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model11.fit(X_12,y, epochs=12, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model11.predict(X_12))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model11.predict(X_12)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOJuvqQX7KbF",
    "outputId": "ea297bcc-bab9-4b09-e527-796c0e17fa64"
   },
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_134 (Dense)           (None, 12)                156       \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 10)                120       \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 794\n",
      "Trainable params: 794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 12) (None, 12)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 12) (None, 11)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 11) (None, 10)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 10) (None, 9)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 9) (None, 8)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 8) (None, 7)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 7) (None, 6)\n",
      "\n",
      "\n",
      " layer_8 :  (None, 6) (None, 5)\n",
      "\n",
      "\n",
      " layer_9 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_10 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_11 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_12 :  (None, 2) (None, 1)\n",
      "Epoch 1/12\n",
      "63/63 - 1s - loss: 3977.1975 - 1s/epoch - 23ms/step\n",
      "Epoch 2/12\n",
      "63/63 - 0s - loss: 3947.8979 - 211ms/epoch - 3ms/step\n",
      "Epoch 3/12\n",
      "63/63 - 0s - loss: 3930.3071 - 201ms/epoch - 3ms/step\n",
      "Epoch 4/12\n",
      "63/63 - 0s - loss: 3925.7471 - 195ms/epoch - 3ms/step\n",
      "Epoch 5/12\n",
      "63/63 - 0s - loss: 3924.0413 - 233ms/epoch - 4ms/step\n",
      "Epoch 6/12\n",
      "63/63 - 0s - loss: 3923.1506 - 219ms/epoch - 3ms/step\n",
      "Epoch 7/12\n",
      "63/63 - 0s - loss: 3922.6072 - 179ms/epoch - 3ms/step\n",
      "Epoch 8/12\n",
      "63/63 - 0s - loss: 3922.2415 - 227ms/epoch - 4ms/step\n",
      "Epoch 9/12\n",
      "63/63 - 0s - loss: 3921.9775 - 250ms/epoch - 4ms/step\n",
      "Epoch 10/12\n",
      "63/63 - 0s - loss: 3921.7751 - 216ms/epoch - 3ms/step\n",
      "Epoch 11/12\n",
      "63/63 - 0s - loss: 3921.6155 - 157ms/epoch - 2ms/step\n",
      "Epoch 12/12\n",
      "63/63 - 0s - loss: 3921.4888 - 158ms/epoch - 3ms/step\n",
      "[[0.9958976]\n",
      " [0.9958976]\n",
      " [0.9958976]\n",
      " ...\n",
      " [0.9958976]\n",
      " [0.9958976]\n",
      " [0.9958976]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#keras1.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=2, activation='sigmoid', input_dim = 2)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=1, activation='sigmoid')\n",
    "model.add(layer_2)\n",
    "\n",
    "\n",
    "print(model.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model.fit(X,y, epochs=2, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model.predict(X))\n",
    "\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model.predict(X)[0])\n",
    "\n",
    "#keras2.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model2 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=1, activation='sigmoid', input_dim = 3)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model2.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=2, activation='sigmoid')\n",
    "model2.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=1, activation='sigmoid')\n",
    "model2.add(layer_3)\n",
    "\n",
    "\n",
    "print(model2.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model2.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model2.fit(X_train,y, epochs=3, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model2.predict(X_train))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model2.predict(X_train)[0])\n",
    "\n",
    "#keras3.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model3 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=1, activation='sigmoid', input_dim = 4)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model3.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=2, activation='sigmoid')\n",
    "model3.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=2, activation='sigmoid')\n",
    "model3.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=1, activation='sigmoid')\n",
    "model3.add(layer_4)\n",
    "\n",
    "print(model3.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model3.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model3.fit(X_4,y, epochs=4, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model3.predict(X_4))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model3.predict(X_4)[0])\n",
    "\n",
    "#keras4.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model4 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=1, activation='sigmoid', input_dim = 5)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model4.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=2, activation='sigmoid')\n",
    "model4.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=3, activation='sigmoid')\n",
    "model4.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=2, activation='sigmoid')\n",
    "model4.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=1, activation='sigmoid')\n",
    "model4.add(layer_5)\n",
    "\n",
    "print(model4.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_4.input_shape, layer_5.output_shape)\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model4.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model4.fit(X_5,y, epochs=5, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model4.predict(X_5))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model4.predict(X_5)[0])\n",
    "\n",
    "#keras5.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model5 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=1, activation='sigmoid', input_dim = 6)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model5.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=2, activation='sigmoid')\n",
    "model5.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=3, activation='sigmoid')\n",
    "model5.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=3, activation='sigmoid')\n",
    "model5.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=2, activation='sigmoid')\n",
    "model5.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=1, activation='sigmoid')\n",
    "model5.add(layer_6)\n",
    "\n",
    "print(model5.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model5.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model5.fit(X_6,y, epochs=6, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model5.predict(X_6))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model5.predict(X_6)[0])\n",
    "\n",
    "#keras6.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model6 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=1, activation='sigmoid', input_dim = 7)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model6.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=2, activation='sigmoid')\n",
    "model6.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=3, activation='sigmoid')\n",
    "model6.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=4, activation='sigmoid')\n",
    "model6.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=3, activation='sigmoid')\n",
    "model6.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=2, activation='sigmoid')\n",
    "model6.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=1, activation='sigmoid')\n",
    "model6.add(layer_7)\n",
    "\n",
    "print(model6.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model6.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model6.fit(X_7,y, epochs=7, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model6.predict(X_7))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model6.predict(X_7)[0])\n",
    "\n",
    "\n",
    "#keras7.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model7 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=1, activation='sigmoid', input_dim = 8)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model7.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=2, activation='sigmoid')\n",
    "model7.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=3, activation='sigmoid')\n",
    "model7.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=4, activation='sigmoid')\n",
    "model7.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=4, activation='sigmoid')\n",
    "model7.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=3, activation='sigmoid')\n",
    "model7.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=2, activation='sigmoid')\n",
    "model7.add(layer_7)\n",
    "#layer 8\n",
    "layer_8 = Dense(units=1, activation='sigmoid')\n",
    "model7.add(layer_8)\n",
    "\n",
    "print(model7.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "print(\"\\n\\n layer_8 : \", layer_8.input_shape, layer_8.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model7.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model7.fit(X_8,y, epochs=8, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model7.predict(X_8))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model7.predict(X_8)[0])\n",
    "\n",
    "#keras8.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model8 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=1, activation='sigmoid', input_dim = 9)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model8.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=2, activation='sigmoid')\n",
    "model8.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=3, activation='sigmoid')\n",
    "model8.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=4, activation='sigmoid')\n",
    "model8.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=5, activation='sigmoid')\n",
    "model8.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=4, activation='sigmoid')\n",
    "model8.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=3, activation='sigmoid')\n",
    "model8.add(layer_7)\n",
    "#layer 8\n",
    "layer_8 = Dense(units=2, activation='sigmoid')\n",
    "model8.add(layer_8)\n",
    "#layer 9\n",
    "layer_9 = Dense(units=1, activation='sigmoid')\n",
    "model8.add(layer_9)\n",
    "\n",
    "print(model8.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "print(\"\\n\\n layer_8 : \", layer_8.input_shape, layer_8.output_shape)\n",
    "print(\"\\n\\n layer_9 : \", layer_9.input_shape, layer_9.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model8.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model8.fit(X_9,y, epochs=9, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model8.predict(X_9))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model8.predict(X_9)[0])\n",
    "\n",
    "#keras9.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model9 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=1, activation='sigmoid', input_dim = 10)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model9.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=2, activation='sigmoid')\n",
    "model9.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=3, activation='sigmoid')\n",
    "model9.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=4, activation='sigmoid')\n",
    "model9.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=5, activation='sigmoid')\n",
    "model9.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=5, activation='sigmoid')\n",
    "model9.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=4, activation='sigmoid')\n",
    "model9.add(layer_7)\n",
    "#layer 8\n",
    "layer_8 = Dense(units=3, activation='sigmoid')\n",
    "model9.add(layer_8)\n",
    "#layer 9\n",
    "layer_9 = Dense(units=2, activation='sigmoid')\n",
    "model9.add(layer_9)\n",
    "#layer 10\n",
    "layer_10 = Dense(units=1, activation='sigmoid')\n",
    "model9.add(layer_10)\n",
    "\n",
    "print(model9.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "print(\"\\n\\n layer_8 : \", layer_8.input_shape, layer_8.output_shape)\n",
    "print(\"\\n\\n layer_9 : \", layer_9.input_shape, layer_9.output_shape)\n",
    "print(\"\\n\\n layer_10 : \", layer_10.input_shape, layer_10.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model9.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model9.fit(X_10,y, epochs=10, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model9.predict(X_10))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model9.predict(X_10)[0])\n",
    "\n",
    "#keras10.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model10 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=1, activation='sigmoid', input_dim = 11)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model10.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=2, activation='sigmoid')\n",
    "model10.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=3, activation='sigmoid')\n",
    "model10.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=4, activation='sigmoid')\n",
    "model10.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=5, activation='sigmoid')\n",
    "model10.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=6, activation='sigmoid')\n",
    "model10.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=5, activation='sigmoid')\n",
    "model10.add(layer_7)\n",
    "#layer 8\n",
    "layer_8 = Dense(units=4, activation='sigmoid')\n",
    "model10.add(layer_8)\n",
    "#layer 9\n",
    "layer_9 = Dense(units=3, activation='sigmoid')\n",
    "model10.add(layer_9)\n",
    "#layer 10\n",
    "layer_10 = Dense(units=2, activation='sigmoid')\n",
    "model10.add(layer_10)\n",
    "#layer 11\n",
    "layer_11 = Dense(units=1, activation='sigmoid')\n",
    "model10.add(layer_11)\n",
    "\n",
    "print(model10.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "print(\"\\n\\n layer_8 : \", layer_8.input_shape, layer_8.output_shape)\n",
    "print(\"\\n\\n layer_9 : \", layer_9.input_shape, layer_9.output_shape)\n",
    "print(\"\\n\\n layer_10 : \", layer_10.input_shape, layer_10.output_shape)\n",
    "print(\"\\n\\n layer_11 : \", layer_11.input_shape, layer_11.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model10.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model10.fit(X_11,y, epochs=11, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model10.predict(X_11))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model10.predict(X_11)[0])\n",
    "\n",
    "#keras11.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define first architecture of the model\n",
    "#\n",
    "model11 = Sequential()    # creates an empty sequential model \n",
    "# layer 1\n",
    "layer_1 = Dense(units=1, activation='sigmoid', input_dim = 12)  ## change it to 3, 4, 5, 6, .. to see results\n",
    "model11.add(layer_1)\n",
    "# layer 2\n",
    "layer_2 = Dense(units=2, activation='sigmoid')\n",
    "model11.add(layer_2)\n",
    "#layer 3\n",
    "layer_3 = Dense(units=3, activation='sigmoid')\n",
    "model11.add(layer_3)\n",
    "#layer 4\n",
    "layer_4 = Dense(units=4, activation='sigmoid')\n",
    "model11.add(layer_4)\n",
    "#layer 5\n",
    "layer_5 = Dense(units=5, activation='sigmoid')\n",
    "model11.add(layer_5)\n",
    "#layer 6\n",
    "layer_6 = Dense(units=6, activation='sigmoid')\n",
    "model11.add(layer_6)\n",
    "#layer 7\n",
    "layer_7 = Dense(units=6, activation='sigmoid')\n",
    "model11.add(layer_7)\n",
    "#layer 8\n",
    "layer_8 = Dense(units=5, activation='sigmoid')\n",
    "model11.add(layer_8)\n",
    "#layer 9\n",
    "layer_9 = Dense(units=4, activation='sigmoid')\n",
    "model11.add(layer_9)\n",
    "#layer 10\n",
    "layer_10 = Dense(units=3, activation='sigmoid')\n",
    "model11.add(layer_10)\n",
    "#layer 11\n",
    "layer_11 = Dense(units=2, activation='sigmoid')\n",
    "model11.add(layer_11)\n",
    "#layer 12\n",
    "layer_12 = Dense(units=1, activation='sigmoid')\n",
    "model11.add(layer_12)\n",
    "\n",
    "print(model11.summary())  # to verify model structure\n",
    "\n",
    "print(\"\\n\\n layer_1 : \", layer_1.input_shape, layer_1.output_shape)\n",
    "print(\"\\n\\n layer_2 : \", layer_2.input_shape, layer_2.output_shape)\n",
    "print(\"\\n\\n layer_3 : \", layer_3.input_shape, layer_3.output_shape)\n",
    "print(\"\\n\\n layer_4 : \", layer_4.input_shape, layer_4.output_shape)\n",
    "print(\"\\n\\n layer_5 : \", layer_5.input_shape, layer_5.output_shape)\n",
    "print(\"\\n\\n layer_6 : \", layer_6.input_shape, layer_6.output_shape)\n",
    "print(\"\\n\\n layer_7 : \", layer_7.input_shape, layer_7.output_shape)\n",
    "print(\"\\n\\n layer_8 : \", layer_8.input_shape, layer_8.output_shape)\n",
    "print(\"\\n\\n layer_9 : \", layer_9.input_shape, layer_9.output_shape)\n",
    "print(\"\\n\\n layer_10 : \", layer_10.input_shape, layer_10.output_shape)\n",
    "print(\"\\n\\n layer_11 : \", layer_11.input_shape, layer_11.output_shape)\n",
    "print(\"\\n\\n layer_12 : \", layer_12.input_shape, layer_12.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# tell Keras what loss,optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model11.compile(loss='mean_squared_error', optimizer =opt)\n",
    "# at this stage, the model is not done yet.\n",
    "\n",
    "# now for training data\n",
    "\n",
    "# np.random.seed(9)\n",
    "# X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "# y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# training\n",
    "model11.fit(X_12,y, epochs=12, verbose=2,  max_queue_size = 40)\n",
    "\n",
    "\n",
    "\n",
    "# now the model is ready. you can use it for prediction\n",
    "\n",
    "# we check it on training data\n",
    "print(model11.predict(X_12))\n",
    "\n",
    "# good to test on new data, test data.\n",
    "lst.append(model11.predict(X_12)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngF9nCPy70_q",
    "outputId": "913b80a0-8f4e-4d95-a649-6e48d8c672fd"
   },
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_146 (Dense)           (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 2) (None, 2)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 2) (None, 1)\n",
      "Epoch 1/2\n",
      "63/63 - 0s - loss: 3971.1680 - 400ms/epoch - 6ms/step\n",
      "Epoch 2/2\n",
      "63/63 - 0s - loss: 3955.1023 - 71ms/epoch - 1ms/step\n",
      "[[0.76626456]\n",
      " [0.76626456]\n",
      " [0.76626456]\n",
      " ...\n",
      " [0.76626456]\n",
      " [0.76626456]\n",
      " [0.76626456]]\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_148 (Dense)           (None, 1)                 4         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 3) (None, 1)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 1) (None, 2)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 2) (None, 1)\n",
      "Epoch 1/3\n",
      "63/63 - 0s - loss: 3990.4512 - 449ms/epoch - 7ms/step\n",
      "Epoch 2/3\n",
      "63/63 - 0s - loss: 3958.1057 - 73ms/epoch - 1ms/step\n",
      "Epoch 3/3\n",
      "63/63 - 0s - loss: 3943.4592 - 70ms/epoch - 1ms/step\n",
      "[[0.84791243]\n",
      " [0.84791243]\n",
      " [0.84791243]\n",
      " ...\n",
      " [0.84791243]\n",
      " [0.84791243]\n",
      " [0.84791243]]\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_151 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18\n",
      "Trainable params: 18\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 4) (None, 1)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 1) (None, 2)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 2) (None, 2)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 2) (None, 1)\n",
      "Epoch 1/4\n",
      "63/63 - 0s - loss: 3938.9697 - 474ms/epoch - 8ms/step\n",
      "Epoch 2/4\n",
      "63/63 - 0s - loss: 3927.8623 - 79ms/epoch - 1ms/step\n",
      "Epoch 3/4\n",
      "63/63 - 0s - loss: 3924.7637 - 75ms/epoch - 1ms/step\n",
      "Epoch 4/4\n",
      "63/63 - 0s - loss: 3923.4172 - 74ms/epoch - 1ms/step\n",
      "[[0.9827498]\n",
      " [0.9827498]\n",
      " [0.9827498]\n",
      " ...\n",
      " [0.9827498]\n",
      " [0.9827498]\n",
      " [0.9827498]]\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_155 (Dense)           (None, 1)                 6         \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 5) (None, 1)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 1) (None, 2)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 2) (None, 3)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 3) (None, 1)\n",
      "Epoch 1/5\n",
      "63/63 - 1s - loss: 3968.3308 - 514ms/epoch - 8ms/step\n",
      "Epoch 2/5\n",
      "63/63 - 0s - loss: 3936.2234 - 78ms/epoch - 1ms/step\n",
      "Epoch 3/5\n",
      "63/63 - 0s - loss: 3925.8584 - 82ms/epoch - 1ms/step\n",
      "Epoch 4/5\n",
      "63/63 - 0s - loss: 3923.5356 - 79ms/epoch - 1ms/step\n",
      "Epoch 5/5\n",
      "63/63 - 0s - loss: 3922.6265 - 78ms/epoch - 1ms/step\n",
      "[[0.988194]\n",
      " [0.988194]\n",
      " [0.988194]\n",
      " ...\n",
      " [0.988194]\n",
      " [0.988194]\n",
      " [0.988194]]\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 1)                 7         \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43\n",
      "Trainable params: 43\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 6) (None, 1)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 1) (None, 2)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 2) (None, 3)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 3) (None, 3)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 2) (None, 1)\n",
      "Epoch 1/6\n",
      "63/63 - 1s - loss: 3941.7515 - 580ms/epoch - 9ms/step\n",
      "Epoch 2/6\n",
      "63/63 - 0s - loss: 3925.9517 - 79ms/epoch - 1ms/step\n",
      "Epoch 3/6\n",
      "63/63 - 0s - loss: 3923.2668 - 80ms/epoch - 1ms/step\n",
      "Epoch 4/6\n",
      "63/63 - 0s - loss: 3922.3828 - 83ms/epoch - 1ms/step\n",
      "Epoch 5/6\n",
      "63/63 - 0s - loss: 3921.9485 - 87ms/epoch - 1ms/step\n",
      "Epoch 6/6\n",
      "63/63 - 0s - loss: 3921.6965 - 82ms/epoch - 1ms/step\n",
      "[[0.99446905]\n",
      " [0.99446905]\n",
      " [0.99446905]\n",
      " ...\n",
      " [0.99446905]\n",
      " [0.99446905]\n",
      " [0.99446905]]\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_166 (Dense)           (None, 1)                 8         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 4)                 16        \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63\n",
      "Trainable params: 63\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 7) (None, 1)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 1) (None, 2)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 2) (None, 3)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 3) (None, 4)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 2) (None, 1)\n",
      "Epoch 1/7\n",
      "63/63 - 1s - loss: 3956.8091 - 598ms/epoch - 9ms/step\n",
      "Epoch 2/7\n",
      "63/63 - 0s - loss: 3931.3530 - 82ms/epoch - 1ms/step\n",
      "Epoch 3/7\n",
      "63/63 - 0s - loss: 3926.1001 - 85ms/epoch - 1ms/step\n",
      "Epoch 4/7\n",
      "63/63 - 0s - loss: 3924.1575 - 86ms/epoch - 1ms/step\n",
      "Epoch 5/7\n",
      "63/63 - 0s - loss: 3923.1863 - 98ms/epoch - 2ms/step\n",
      "Epoch 6/7\n",
      "63/63 - 0s - loss: 3922.6187 - 90ms/epoch - 1ms/step\n",
      "Epoch 7/7\n",
      "63/63 - 0s - loss: 3922.2529 - 84ms/epoch - 1ms/step\n",
      "[[0.99014926]\n",
      " [0.99014926]\n",
      " [0.99014926]\n",
      " ...\n",
      " [0.99014926]\n",
      " [0.99014926]\n",
      " [0.99014926]]\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_173 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 4)                 16        \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84\n",
      "Trainable params: 84\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 8) (None, 1)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 1) (None, 2)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 2) (None, 3)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 3) (None, 4)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 4) (None, 4)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_8 :  (None, 2) (None, 1)\n",
      "Epoch 1/8\n",
      "63/63 - 1s - loss: 3980.5679 - 642ms/epoch - 10ms/step\n",
      "Epoch 2/8\n",
      "63/63 - 0s - loss: 3955.2329 - 88ms/epoch - 1ms/step\n",
      "Epoch 3/8\n",
      "63/63 - 0s - loss: 3943.1501 - 90ms/epoch - 1ms/step\n",
      "Epoch 4/8\n",
      "63/63 - 0s - loss: 3935.3625 - 86ms/epoch - 1ms/step\n",
      "Epoch 5/8\n",
      "63/63 - 0s - loss: 3928.5146 - 85ms/epoch - 1ms/step\n",
      "Epoch 6/8\n",
      "63/63 - 0s - loss: 3924.6326 - 89ms/epoch - 1ms/step\n",
      "Epoch 7/8\n",
      "63/63 - 0s - loss: 3923.2832 - 94ms/epoch - 1ms/step\n",
      "Epoch 8/8\n",
      "63/63 - 0s - loss: 3922.6279 - 87ms/epoch - 1ms/step\n",
      "[[0.98769546]\n",
      " [0.98769546]\n",
      " [0.98769546]\n",
      " ...\n",
      " [0.98769546]\n",
      " [0.98769546]\n",
      " [0.98769546]]\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_181 (Dense)           (None, 1)                 10        \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 4)                 16        \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 5)                 25        \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 114\n",
      "Trainable params: 114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 9) (None, 1)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 1) (None, 2)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 2) (None, 3)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 3) (None, 4)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 4) (None, 5)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_8 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_9 :  (None, 2) (None, 1)\n",
      "Epoch 1/9\n",
      "63/63 - 1s - loss: 3941.9763 - 689ms/epoch - 11ms/step\n",
      "Epoch 2/9\n",
      "63/63 - 0s - loss: 3925.6899 - 91ms/epoch - 1ms/step\n",
      "Epoch 3/9\n",
      "63/63 - 0s - loss: 3923.1086 - 95ms/epoch - 2ms/step\n",
      "Epoch 4/9\n",
      "63/63 - 0s - loss: 3922.2649 - 95ms/epoch - 2ms/step\n",
      "Epoch 5/9\n",
      "63/63 - 0s - loss: 3921.8613 - 100ms/epoch - 2ms/step\n",
      "Epoch 6/9\n",
      "63/63 - 0s - loss: 3921.6277 - 90ms/epoch - 1ms/step\n",
      "Epoch 7/9\n",
      "63/63 - 0s - loss: 3921.4790 - 87ms/epoch - 1ms/step\n",
      "Epoch 8/9\n",
      "63/63 - 0s - loss: 3921.3765 - 89ms/epoch - 1ms/step\n",
      "Epoch 9/9\n",
      "63/63 - 0s - loss: 3921.3040 - 88ms/epoch - 1ms/step\n",
      "[[0.9972669]\n",
      " [0.9972669]\n",
      " [0.9972669]\n",
      " ...\n",
      " [0.9972669]\n",
      " [0.9972669]\n",
      " [0.9972669]]\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_190 (Dense)           (None, 1)                 11        \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 4)                 16        \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 5)                 25        \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145\n",
      "Trainable params: 145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 10) (None, 1)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 1) (None, 2)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 2) (None, 3)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 3) (None, 4)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 4) (None, 5)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 5) (None, 5)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_8 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_9 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_10 :  (None, 2) (None, 1)\n",
      "Epoch 1/10\n",
      "63/63 - 1s - loss: 3942.2947 - 723ms/epoch - 11ms/step\n",
      "Epoch 2/10\n",
      "63/63 - 0s - loss: 3928.7451 - 89ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "63/63 - 0s - loss: 3925.2507 - 88ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "63/63 - 0s - loss: 3923.7410 - 91ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "63/63 - 0s - loss: 3922.9343 - 91ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "63/63 - 0s - loss: 3922.4458 - 97ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "63/63 - 0s - loss: 3922.1265 - 104ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "63/63 - 0s - loss: 3921.9036 - 93ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "63/63 - 0s - loss: 3921.7410 - 98ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "63/63 - 0s - loss: 3921.6174 - 99ms/epoch - 2ms/step\n",
      "[[0.9947778]\n",
      " [0.9947778]\n",
      " [0.9947778]\n",
      " ...\n",
      " [0.9947778]\n",
      " [0.9947778]\n",
      " [0.9947778]]\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_200 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 4)                 16        \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 5)                 25        \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 6)                 36        \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 187\n",
      "Trainable params: 187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 11) (None, 1)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 1) (None, 2)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 2) (None, 3)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 3) (None, 4)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 4) (None, 5)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 5) (None, 6)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 6) (None, 5)\n",
      "\n",
      "\n",
      " layer_8 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_9 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_10 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_11 :  (None, 2) (None, 1)\n",
      "Epoch 1/11\n",
      "63/63 - 1s - loss: 3943.7517 - 789ms/epoch - 13ms/step\n",
      "Epoch 2/11\n",
      "63/63 - 0s - loss: 3926.8887 - 98ms/epoch - 2ms/step\n",
      "Epoch 3/11\n",
      "63/63 - 0s - loss: 3923.8093 - 106ms/epoch - 2ms/step\n",
      "Epoch 4/11\n",
      "63/63 - 0s - loss: 3922.7107 - 104ms/epoch - 2ms/step\n",
      "Epoch 5/11\n",
      "63/63 - 0s - loss: 3922.1697 - 95ms/epoch - 2ms/step\n",
      "Epoch 6/11\n",
      "63/63 - 0s - loss: 3921.8567 - 108ms/epoch - 2ms/step\n",
      "Epoch 7/11\n",
      "63/63 - 0s - loss: 3921.6550 - 98ms/epoch - 2ms/step\n",
      "Epoch 8/11\n",
      "63/63 - 0s - loss: 3921.5186 - 99ms/epoch - 2ms/step\n",
      "Epoch 9/11\n",
      "63/63 - 0s - loss: 3921.4192 - 113ms/epoch - 2ms/step\n",
      "Epoch 10/11\n",
      "63/63 - 0s - loss: 3921.3452 - 98ms/epoch - 2ms/step\n",
      "Epoch 11/11\n",
      "63/63 - 0s - loss: 3921.2891 - 107ms/epoch - 2ms/step\n",
      "[[0.9973445]\n",
      " [0.9973445]\n",
      " [0.9973445]\n",
      " ...\n",
      " [0.9973445]\n",
      " [0.9973445]\n",
      " [0.9973445]]\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_211 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 4)                 16        \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 5)                 25        \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 6)                 36        \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 230\n",
      "Trainable params: 230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " layer_1 :  (None, 12) (None, 1)\n",
      "\n",
      "\n",
      " layer_2 :  (None, 1) (None, 2)\n",
      "\n",
      "\n",
      " layer_3 :  (None, 2) (None, 3)\n",
      "\n",
      "\n",
      " layer_4 :  (None, 3) (None, 4)\n",
      "\n",
      "\n",
      " layer_5 :  (None, 4) (None, 5)\n",
      "\n",
      "\n",
      " layer_6 :  (None, 5) (None, 6)\n",
      "\n",
      "\n",
      " layer_7 :  (None, 6) (None, 6)\n",
      "\n",
      "\n",
      " layer_8 :  (None, 6) (None, 5)\n",
      "\n",
      "\n",
      " layer_9 :  (None, 5) (None, 4)\n",
      "\n",
      "\n",
      " layer_10 :  (None, 4) (None, 3)\n",
      "\n",
      "\n",
      " layer_11 :  (None, 3) (None, 2)\n",
      "\n",
      "\n",
      " layer_12 :  (None, 2) (None, 1)\n",
      "Epoch 1/12\n",
      "63/63 - 1s - loss: 3940.6731 - 821ms/epoch - 13ms/step\n",
      "Epoch 2/12\n",
      "63/63 - 0s - loss: 3927.2214 - 96ms/epoch - 2ms/step\n",
      "Epoch 3/12\n",
      "63/63 - 0s - loss: 3923.2949 - 114ms/epoch - 2ms/step\n",
      "Epoch 4/12\n",
      "63/63 - 0s - loss: 3922.2405 - 101ms/epoch - 2ms/step\n",
      "Epoch 5/12\n",
      "63/63 - 0s - loss: 3921.8083 - 102ms/epoch - 2ms/step\n",
      "Epoch 6/12\n",
      "63/63 - 0s - loss: 3921.5742 - 103ms/epoch - 2ms/step\n",
      "Epoch 7/12\n",
      "63/63 - 0s - loss: 3921.4304 - 101ms/epoch - 2ms/step\n",
      "Epoch 8/12\n",
      "63/63 - 0s - loss: 3921.3347 - 102ms/epoch - 2ms/step\n",
      "Epoch 9/12\n",
      "63/63 - 0s - loss: 3921.2646 - 101ms/epoch - 2ms/step\n",
      "Epoch 10/12\n",
      "63/63 - 0s - loss: 3921.2151 - 103ms/epoch - 2ms/step\n",
      "Epoch 11/12\n",
      "63/63 - 0s - loss: 3921.1755 - 102ms/epoch - 2ms/step\n",
      "Epoch 12/12\n",
      "63/63 - 0s - loss: 3921.1455 - 98ms/epoch - 2ms/step\n",
      "[[0.99845743]\n",
      " [0.99845743]\n",
      " [0.99845743]\n",
      " ...\n",
      " [0.99845743]\n",
      " [0.99845743]\n",
      " [0.99845743]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# regression analysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X_train = [2,3,4,5,6,7,8,10,11,12,13]\n",
    "y_train = [0.94913673, 0.9801116, 0.9924147, 0.9930438, 0.9895524, 0.99626696, 0.9925206, 0.99731386, 0.9982563, 0.97462773, 0.9958976]\n",
    "X_test = [2,3,4,5,6,7,8,10,11,12,13]\n",
    "y_test = [0.76626456, 0.84791243, 0.9827498, 0.988194, 0.99446905, 0.99014926, 0.98769546, 0.9972669, 0.9947778, 0.9973445, 0.99845743]\n",
    "\n",
    "poly1 = np.poly1d(np.polyfit(X_train, y_train, 6))\n",
    "poly2 = np.poly1d(np.polyfit(X_test, y_test, 6))\n",
    "line = np.linspace(1, 22, 100)\n",
    "plt.figure(figsize=(6,10))\n",
    "plt.scatter(X_train, y_train, label='True Points')\n",
    "plt.scatter(X_test, y_test, label='True Points')\n",
    "plt.plot(line, poly1(line))\n",
    "plt.plot(line, poly2(line))\n",
    "plt.title('Comparison between Accuracies of 2 Types of Neuro-network Architecture')\n",
    "plt.xlabel('Inputs')\n",
    "plt.ylabel('Accuracy(0~1)')\n",
    "plt.axis([0, 15, 0.7, 1.4])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "6WjI3DnW-H3B",
    "outputId": "fd2c45ef-8ebc-461e-96b0-40cba238c6e4"
   },
   "execution_count": 78,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x720 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(X_train\n",
    "      )"
   ],
   "metadata": {
    "id": "-2-ub2cQD5oe"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
