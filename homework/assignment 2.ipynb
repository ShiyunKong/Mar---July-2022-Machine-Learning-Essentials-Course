{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 137323,
     "status": "ok",
     "timestamp": 1653802609235,
     "user": {
      "displayName": "Timothy Kong",
      "userId": "01106019165194270676"
     },
     "user_tz": -480
    },
    "id": "URAgGFe67ZNH",
    "outputId": "065c06c1-cbf1-41f2-cd6d-0195b9e9b400"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m/Users/timkong/Main Storge/编程/assignment 2.ipynb Cell 1'\u001B[0m in \u001B[0;36m<cell line: 19>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/timkong/Main%20Storge/%E7%BC%96%E7%A8%8B/assignment%202.ipynb#ch0000000?line=0'>1</a>\u001B[0m \u001B[39m'''\u001B[39;00m\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/timkong/Main%20Storge/%E7%BC%96%E7%A8%8B/assignment%202.ipynb#ch0000000?line=1'>2</a>\u001B[0m \u001B[39mAssignment II\u001B[39;00m\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/timkong/Main%20Storge/%E7%BC%96%E7%A8%8B/assignment%202.ipynb#ch0000000?line=2'>3</a>\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/timkong/Main%20Storge/%E7%BC%96%E7%A8%8B/assignment%202.ipynb#ch0000000?line=16'>17</a>\u001B[0m \u001B[39mEnjoy!!\u001B[39;00m\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/timkong/Main%20Storge/%E7%BC%96%E7%A8%8B/assignment%202.ipynb#ch0000000?line=17'>18</a>\u001B[0m \u001B[39m'''\u001B[39;00m\n\u001B[0;32m---> <a href='vscode-notebook-cell:/Users/timkong/Main%20Storge/%E7%BC%96%E7%A8%8B/assignment%202.ipynb#ch0000000?line=18'>19</a>\u001B[0m \u001B[39mfrom\u001B[39;00m \u001B[39mgoogle\u001B[39;00m\u001B[39m.\u001B[39;00m\u001B[39mcolab\u001B[39;00m \u001B[39mimport\u001B[39;00m drive\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/timkong/Main%20Storge/%E7%BC%96%E7%A8%8B/assignment%202.ipynb#ch0000000?line=19'>20</a>\u001B[0m drive\u001B[39m.\u001B[39mmount(\u001B[39m'\u001B[39m\u001B[39m/content/drive\u001B[39m\u001B[39m'\u001B[39m)\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/timkong/Main%20Storge/%E7%BC%96%E7%A8%8B/assignment%202.ipynb#ch0000000?line=20'>21</a>\u001B[0m \u001B[39mimport\u001B[39;00m \u001B[39mnumpy\u001B[39;00m \u001B[39mas\u001B[39;00m \u001B[39mnp\u001B[39;00m \n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Assignment II\n",
    "\n",
    "Due: May 29, 2022.\n",
    "Pick a dataset of your choice. From UCI classification datasets\n",
    "(https://archive.ics.uci.edu/ml/datasets.php?format=&task=cla&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table)\n",
    "Use the SVM  (svm.py) , Naïve Bayes (gaussNB.py) ,  as we learned in lecture 2 to classify the data\n",
    "\n",
    "You can create also test data and check percentage of error – how good the algorithm performed.\n",
    "Play with relevant parameters and determine the accuracy of the method. Print also confusion matrix to get a good sense\n",
    "of the error made by the model.\n",
    "\n",
    "Submit:\n",
    "1) code in Python\n",
    "2) a word file summarizing the result include some measure of performance such as confusion matrix, and accuracy.\n",
    "\n",
    "Enjoy!!\n",
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "dataframe = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/anime.csv\", sep=\",\")\n",
    "dataframe['episodes'] = pd.to_numeric(dataframe[\"episodes\"], errors='coerce').fillna(1000).astype(int)\n",
    "dataframe.episodes[dataframe.episodes <= 25] = 0\n",
    "dataframe.episodes[dataframe.episodes > 25] = 1\n",
    "selected_column = [5,6]\n",
    "feature_data = dataframe.iloc[:, selected_column]\n",
    "from sklearn.impute import SimpleImputer\n",
    "def imputation(original_data):\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    imputer.fit(original_data)\n",
    "    X = imputer.transform(original_data)\n",
    "    return pd.DataFrame(X, columns=original_data.columns, index=original_data.index)\n",
    "feature_data_imputed = imputation(feature_data)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def MMScaling(original_data):\n",
    "    MMS = MinMaxScaler()\n",
    "    X= MMS.fit_transform(original_data)\n",
    "    return pd.DataFrame(X, columns=original_data.columns,\n",
    "                          index=original_data.index)\n",
    "feature_data_imputed_scaled = MMScaling(feature_data_imputed)\n",
    "label_data = dataframe.iloc[:, 4]\n",
    "label_data_bool = pd.DataFrame(label_data)\n",
    "# GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_set, X_test_set, y_train_set, y_test_set = train_test_split(feature_data_imputed_scaled,label_data_bool, test_size=0.5, random_state=0)\n",
    "print(X_train_set)\n",
    "print(y_train_set)\n",
    "X_train = np.array(X_train_set)\n",
    "y_train = np.array(y_train_set)\n",
    "X_test = np.array(X_test_set)\n",
    "y_test = np.array(y_test_set)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=50, cmap='RdBu')\n",
    "lim = plt.axis()\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=20, cmap='RdBu', alpha=0.1)\n",
    "plt.axis(lim)\n",
    "plt.show()\n",
    "lr = LogisticRegression()\n",
    "nb = GaussianNB()\n",
    "lr_scores = []\n",
    "nb_scores = []\n",
    "train_sizes = range(10, len(X_train), 1000)\n",
    "for train_size in train_sizes:\n",
    "  X_slice, _, y_slice, _ = train_test_split(X_train, y_train, train_size=train_size, stratify=y_train, random_state=11)\n",
    "  nb.fit(X_slice, y_slice)\n",
    "  nb_scores.append(nb.score(X_test, y_test))\n",
    "  lr.fit(X_slice, y_slice)\n",
    "  lr_scores.append(lr.score(X_test, y_test))\n",
    "plt.plot(train_sizes, nb_scores, label='Naïve Bayes')\n",
    "plt.plot(train_sizes, lr_scores, linestyle='--', label='Logistic Regression')\n",
    "plt.title(\"Naïve Bayes and Logistic Regression Accuracies\")\n",
    "plt.xlabel(\"Number of training instances\")\n",
    "plt.ylabel(\"Test set accuracy\")\n",
    "plt.legend()\n",
    "plt.figure(1)\n",
    "y_pred = nb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def find_misses(test, pred):\n",
    "  return[i for i, row in enumerate(test) if row != pred[i]]\n",
    "if __name__ == \"__main__\":\n",
    "  br = \"\\n\"\n",
    "  gnb = GaussianNB().fit(X_train, y_train)\n",
    "  gnb_name = gnb.__class__.__name__\n",
    "  y_pred = gnb.predict(X_test)\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  print (gnb_name + ' \\'test\\' accuracy:', accuracy)\n",
    "  scaler = StandardScaler()\n",
    "  X_train_std = scaler.fit_transform(X_train)\n",
    "  y_train_std = scaler.fit_transform(y_train)\n",
    "  X_test_std = scaler.fit_transform(X_test)\n",
    "  y_test_std = scaler.fit_transform(y_test)\n",
    "  sgd = SGDClassifier(random_state=0, max_iter=1000, tol=0.001)\n",
    "  sgd_name = sgd.__class__.__name__\n",
    "  sgd.fit(X_train_std, y_train)\n",
    "  y_pred = sgd.predict(X_test_std)\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  print (sgd_name + ' \\'test\\' accuracy:', accuracy)\n",
    "  svm = SVC(gamma='auto').fit(X_train_std, y_train)\n",
    "  svm_name = \"SVM\"\n",
    "  y_pred = svm.predict(X_test_std)\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  print (svm_name + ' \\'test\\' accuracy:', accuracy, br)\n",
    "  indx = find_misses(y_test, y_pred)\n",
    "  print(f'total misclassifications {svm_name}:  {len(indx)} {br}')\n",
    "  misses = [(y_pred[row], y_test[row], i)for i, row in enumerate(indx)] \n",
    "  img_indx = misses[0][2]\n",
    "  img_pred = misses[0][0]\n",
    "  img_act = misses[0][1]\n",
    "  text = str(img_pred)\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  plt.figure(2)\n",
    "  ax = plt.axes()\n",
    "  sns.heatmap(cm.T, annot=True, fmt=\"d\",cmap='gist_ncar_r', ax=ax)\n",
    "  title = svm_name + ' confusion matrix'\n",
    "  ax.set_title(title)\n",
    "  plt.xlabel('true value')\n",
    "  plt.ylabel('predicted value')\n",
    "  test_images = X_test[0:4096].reshape(-1, 8, 8)\n",
    "  plt.figure(3)\n",
    "  plt.title('1st misclassifcation')\n",
    "  plt.imshow(test_images[img_indx], cmap=\"gray\", interpolation=\"gaussian\")\n",
    "  plt.text(0, 0.05, text, color=\"r\", bbox=dict(facecolor='white'))\n",
    "  plt.show()\n",
    "\n",
    "# svm\n",
    "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "        # create grid to evaluate model\n",
    "        x = np.linspace(xlim[0], xlim[1], 30)\n",
    "\n",
    "        y = np.linspace(ylim[0], ylim[1], 30)\n",
    "        Y, X = np.meshgrid(y, x)\n",
    "        xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "        P = model.decision_function(xy).reshape(X.shape)\n",
    "        # plot decision boundary and margins\n",
    "        ax.contour(X, Y, P, colors='k',\n",
    "        levels=[-1, 0, 1], alpha=0.5,\n",
    "        linestyles=['--', '-', '--'])\n",
    "        # plot support vectors\n",
    "        if plot_support:\n",
    "            ax.scatter(model.support_vectors_[:, 0],\n",
    "            model.support_vectors_[:, 1], s=300, linewidth=1, facecolors='none');\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "X = X_train\n",
    "y= y_train\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='summer');\n",
    "plt.show()\n",
    "\n",
    "model = SVC(kernel='linear', C=1E10)\n",
    "model.fit(X, y)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='summer')\n",
    "plot_svc_decision_function(model);\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfX0Da7M-Rjp"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNqeGLsTO3d+2qv7/AnEY1V",
   "collapsed_sections": [],
   "name": "assignment 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
